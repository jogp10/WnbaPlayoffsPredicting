{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project - WNBA Playoffs Prediction - G24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data\n",
    "Basketball tournaments are usually split in two parts. First, all teams play each other aiming to achieve the greatest number of wins possible. Then, at the end of the first part of the season, a pre determined number of teams which were able to win the most games are qualified to the playoff season, where they play series of knock-out matches for the trophy.\n",
    "\n",
    "For the 10 years, data from players, teams, coaches, games and several other metrics were gathered and arranged on this dataset. The goal is to use this data to predict which teams will qualify for the playoffs in the next season.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition Format\n",
    "The 12 teams in the WNBA are split into an Eastern Conference and a Western Conference. WNBA fixtures begin with preseason games in May before each team plays 20 home games and 20 road games during the regular season.\n",
    "\n",
    "The aim for every team is to qualify for the Playoffs, which begin in September each year.\n",
    "\n",
    "The WNBA teams with the eight best regular season records regardless of standing qualify for the Playoffs. Higher seeds matchup with lower seeds, so the top seed faces the eight seed, the second seed faces the seven seed and so on.\n",
    "\n",
    "When it comes to betting on the Playoffs, the first round are best-of-three series. The semifinals and final are both best-of-five, meaning WNBA teams need to record three wins to claim victory in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a free service to host our database. The Database is in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Credentials\n",
    "\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "host = config[\"db_host\"]\n",
    "user = config[\"db_user\"]\n",
    "password = config[\"db_password\"]\n",
    "database = config[\"db_database\"]\n",
    "schema = config[\"db_schema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "def execute(query):\n",
    "    cursor.execute(query)\n",
    "    connection.commit()\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def fetch(query):\n",
    "    cursor.execute(query)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "SELECT = \"SELECT * FROM \" + schema + \".\" # + table_name \n",
    "INSERT = \"INSERT INTO \" + schema + \".\" # + table_name + \" VALUES \" + values\n",
    "UPDATE = \"UPDATE \" + schema + \".\" # + table_name + \" SET \" + column_name + \" = \" + value\n",
    "DELETE = \"DELETE FROM \" + schema + \".\"  # + table_name + \" WHERE \" + column_name + \" = \" + value\n",
    "\n",
    "# Test data, year 10\n",
    "TEST_DATA = \"year = 10\"\n",
    "TRAIN_DATA = \"year < 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The data about the players, teams and coaches consist of following relations:\n",
    "\n",
    "    awards_players (96 objects) - each record describes awards and prizes received by players across 10 seasons,\n",
    "    coaches (163 objects) - each record describes all coaches who've managed the teams during the time period,\n",
    "    players (894 objects) - each record contains details of all players,\n",
    "    players_teams (1877 objects) - each record describes the performance of each player for each team they played,\n",
    "    series_post (71 objects) - each record describes the series' results,\n",
    "    teams (143 objects) - each record describes the performance of the teams for each season,\n",
    "    teams_post (81 objects) - each record describes the results of each team at the post-season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players = fetch(SELECT + \"awards_players\") # awards and prizes received by players across 10 seasons,\n",
    "coaches = fetch(SELECT + \"coaches\") # all coaches who've managed the teams during the time period,\n",
    "players = fetch(SELECT + \"players\") # details of all players,\n",
    "players_teams = fetch(SELECT + \"players_teams\") # performance of each player for each team they played,\n",
    "series_post = fetch(SELECT + \"series_post\") # series' results,\n",
    "teams = fetch(SELECT + \"teams\") # performance of the teams for each season,\n",
    "teams_post = fetch(SELECT + \"teams_post\") # results of each team at the post-season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data in a dataframe\n",
    "awards_players_df = pd.DataFrame(awards_players, columns=['playerID', 'award', 'year', 'lgID'])\n",
    "coaches_df = pd.DataFrame(coaches, columns=['coachID', 'year', 'tmID', 'lgID', 'stint', 'won', 'lost', 'post_wins', 'post_losses'])\n",
    "players_df = pd.DataFrame(players, columns=['bioID', 'pos', 'firstseason', 'lastseason', 'height', 'weight', 'college', 'collegeOther', 'birthDate', 'deathDate'])\n",
    "players_teams_df = pd.DataFrame(players_teams, columns=['playerID', 'year', 'stint', 'tmID', 'lgID', 'GP', 'GS', 'minutes', 'points', 'oRebounds', 'dRebounds', 'rebounds', 'assists', 'steals', 'blocks', 'turnovers', 'PF', 'fgAttempted', 'fgMade', 'ftAttempted', 'ftMade', 'threeAttempted', 'threeMade', 'dq', 'PostGP', 'PostGS', 'PostMinutes', 'PostPoints', 'PostoRebounds', 'PostdRebounds', 'PostRebounds', 'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF', 'PostfgAttempted', 'PostfgMade', 'PostftAttempted', 'PostftMade', 'PostthreeAttempted', 'PostthreeMade', 'PostDQ'])\n",
    "series_post_df = pd.DataFrame(series_post, columns=['year', 'round', 'series', 'tmIDWinner', 'lgIDWinner', 'tmIDLoser', 'lgIDLoser', 'W', 'L'])\n",
    "teams_df = pd.DataFrame(teams, columns=['year', 'lgID', 'tmID', 'franchID', 'confID', 'divID', 'rank', 'playoff', 'seeded', 'firstRound', 'semis', 'finals', 'name', 'o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_reb', 'o_asts', 'o_pf', 'o_stl', 'o_to', 'o_blk', 'o_pts', 'd_fgm', 'd_fga', 'd_ftm', 'd_fta', 'd_3pm', 'd_3pa', 'd_oreb', 'd_dreb', 'd_reb', 'd_asts', 'd_pf', 'd_stl', 'd_to', 'd_blk', 'd_pts', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB', 'won', 'lost', 'GP', 'homeW', 'homeL', 'awayW', 'awayL', 'confW', 'confL', 'min', 'attend', 'arena'])\n",
    "teams_post_df = pd.DataFrame(teams_post, columns=['year', 'tmID', 'lgID', 'W', 'L'])\n",
    "\n",
    "#make a dictionary with all the dataframes\n",
    "dfs = {'awards_players_df': awards_players_df, 'coaches_df': coaches_df, 'players_df': players_df, 'players_teams_df': players_teams_df, 'series_post_df': series_post_df, 'teams_df': teams_df, 'teams_post_df': teams_post_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with a Exploratory Data Analysis. There are 7 different tables, with different sizes both in lines and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each table, print the table name, number of rows and columns\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print(dfs[df].shape,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things we noticed is that all the tables have an \"League ID\" (lgID) attribute. As the WNBA is the only league we are covering, and there is no variability in this column, we can drop it, as well as other columns that may have always the same content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns whose values are always the same\n",
    "for df in dfs:\n",
    "    for col in dfs[df].columns:\n",
    "        if len(dfs[df][col].unique()) == 1:\n",
    "            print(df, col)\n",
    "            dfs[df].drop(col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, we also need to drop the death athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop rows where death date is not 0000-00-00\n",
    "players_df = players_df[players_df['deathDate'] == '0000-00-00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Describing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a head of each table\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print(dfs[df].head(), '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a describe of each table\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print(dfs[df].describe(include='all'), '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # do a info of each table\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print(dfs[df].info(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a isnull of each table to see if there are null values\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print(dfs[df].isnull().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the value counts for each column of type object\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    for col in dfs[df].columns:\n",
    "        if dfs[df][col].dtype == 'object':\n",
    "            print(dfs[df][col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMORA UNS SEGUNDOS A IMPRIMIR TUDO, não sei bem que interpretar, marca demasiados outliers\n",
    "# check for outliers\n",
    "for df in dfs:\n",
    "    \n",
    "    continue # comment this line to run the code\n",
    "    \n",
    "    print(df)\n",
    "    \n",
    "    # do box plots of the numerical columns\n",
    "    for col in dfs[df].columns:\n",
    "        if dfs[df][col].dtype != 'object':\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            # sns.boxplot(x=dfs[df][col])\n",
    "            sns.violinplot(x=dfs[df][col])\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#APENAS exemplo, olhando para a tabela teams, nada parece natural de combinar\n",
    "# for table teams_df\n",
    "ys = teams_df['attend']\n",
    "x = teams_df['min']\n",
    "\n",
    "colors = ['g' if s == 'Y' else 'r' for s in teams_df['playoff']]\n",
    "plt.ylabel('Attend')\n",
    "plt.xlabel('Min')\n",
    "plt.scatter(x, ys, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tables with a lot of attributes (player_teams 43 and teams_df 61, for example). We will evaluate the correlations and delete the most correlated pairs of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CORRELATION = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_most_correlated(df):\n",
    "\n",
    "    players_teams_df_copy = df.copy()\n",
    "\n",
    "\n",
    "    correlation_matrix = players_teams_df_copy.corr()\n",
    "\n",
    "    sorted_correlations = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.show()\n",
    "\n",
    "    # Get the pairs of attributes with the highest correlation values\n",
    "    most_correlated_pairs = sorted_correlations[sorted_correlations > MAX_CORRELATION]\n",
    "    most_correlated_pairs = most_correlated_pairs[most_correlated_pairs < 1.0]\n",
    "\n",
    "\n",
    "    #delete repeated pairs (e.g. (a,b) and (b,a))\n",
    "    most_correlated_pairs = most_correlated_pairs[::2]\n",
    "    print(most_correlated_pairs)\n",
    "\n",
    "    #drop the attributes with the highest correlation values\n",
    "    for pair in most_correlated_pairs.index:\n",
    "        if pair[0] in players_teams_df_copy.columns:\n",
    "            players_teams_df_copy.drop(pair[0], inplace=True, axis=1)\n",
    "        if pair[1] in players_teams_df_copy.columns:\n",
    "            players_teams_df_copy.drop(pair[1], inplace=True, axis=1)\n",
    "\n",
    "    #print the attributes that were dropped\n",
    "    print(players_teams_df_copy.columns)\n",
    "    return players_teams_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the function for all the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    print(df)\n",
    "    #to make the df actually change, we have to assign it to the df\n",
    "    #df = delete_most_correlated(dfs[df])\n",
    "    delete_most_correlated(dfs[df])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging Tables (FALTAM COISAS ANTES MAS VOU VER SE DÀ PARA IR PENSANDO NISTO)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merged tables:\n",
    "- teams with teams_post, some values are NaN when the team didn't participate in the playoffs\n",
    "- players with players_teams, some values are NaN when the player didn't participate in any team, remove such cases?\n",
    "- awards with players\n",
    "\n",
    "- próximas ideia... listas de valores agregados ou colunas a 0 ou 1 se forem poucos valores diferentes\n",
    "- Is series_post even relevant??"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "teams_post_df = teams_post_df.rename(columns={'W': 'W_post', 'L': 'L_post'})\n",
    "teams_post_df.head()\n",
    "teams_df = teams_df.merge(teams_post_df, on=['tmID', 'year'], how='left')\n",
    "\n",
    "teams_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# join players (bioID) with players_teams (playerID)\n",
    "\n",
    "players_teams_df = players_teams_df.rename(columns={'playerID': 'bioID'})\n",
    "players_teams_df.head()\n",
    "players_df = players_df.merge(players_teams_df, on=['bioID'], how='left')\n",
    "players_df = players_df.rename(columns={'bioID': 'playerID'})\n",
    "players_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge players with awards on playerID and year\n",
    "awards_players_df.head()\n",
    "players_df = players_df.merge(awards_players_df, on=['playerID', 'year'], how='left')\n",
    "#players_df.boxplot(column='points', by='award')\n",
    "players_df['award'].value_counts()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
