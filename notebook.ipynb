{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project - WNBA Playoffs Prediction - G24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data\n",
    "Basketball tournaments are usually split in two parts. First, all teams play each other aiming to achieve the greatest number of wins possible. Then, at the end of the first part of the season, a pre determined number of teams which were able to win the most games are qualified to the playoff season, where they play series of knock-out matches for the trophy.\n",
    "\n",
    "For the 10 years, data from players, teams, coaches, games and several other metrics were gathered and arranged on this dataset. The goal is to use this data to predict which teams will qualify for the playoffs in the next season.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition Format\n",
    "The 12 teams in the WNBA are split into an Eastern Conference and a Western Conference. WNBA fixtures begin with preseason games in May before each team plays 20 home games and 20 road games during the regular season.\n",
    "\n",
    "The aim for every team is to qualify for the Playoffs, which begin in September each year.\n",
    "\n",
    "The WNBA teams with the eight best regular season records regardless of standing qualify for the Playoffs. Higher seeds matchup with lower seeds, so the top seed faces the eight seed, the second seed faces the seven seed and so on.\n",
    "\n",
    "When it comes to betting on the Playoffs, the first round are best-of-three series. The semifinals and final are both best-of-five, meaning WNBA teams need to record three wins to claim victory in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a free service to host our database. The Database is in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Credentials\n",
    "import json\n",
    "\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "host = config[\"db_host\"]\n",
    "user = config[\"db_user\"]\n",
    "password = config[\"db_password\"]\n",
    "database = config[\"db_database\"]\n",
    "schema = config[\"db_schema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "def execute(query):\n",
    "    cursor.execute(query)\n",
    "    connection.commit()\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def fetch(query):\n",
    "    cursor.execute(query)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "SELECT = \"SELECT * FROM \" + schema + \".\" # + table_name \n",
    "INSERT = \"INSERT INTO \" + schema + \".\" # + table_name + \" VALUES \" + values\n",
    "UPDATE = \"UPDATE \" + schema + \".\" # + table_name + \" SET \" + column_name + \" = \" + value\n",
    "DELETE = \"DELETE FROM \" + schema + \".\"  # + table_name + \" WHERE \" + column_name + \" = \" + value\n",
    "\n",
    "# Test data, year 10\n",
    "TEST_DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The data about the players, teams and coaches consist of following relations:\n",
    "\n",
    "    awards_players (96 objects) - each record describes awards and prizes received by players across 10 seasons,\n",
    "    coaches (163 objects) - each record describes all coaches who've managed the teams during the time period,\n",
    "    players (894 objects) - each record contains details of all players,\n",
    "    players_teams (1877 objects) - each record describes the performance of each player for each team they played,\n",
    "    series_post (71 objects) - each record describes the series' results,\n",
    "    teams (143 objects) - each record describes the performance of the teams for each season,\n",
    "    teams_post (81 objects) - each record describes the results of each team at the post-season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players = fetch(SELECT + \"awards_players\") # awards and prizes received by players across 10 seasons,\n",
    "coaches = fetch(SELECT + \"coaches\") # all coaches who've managed the teams during the time period,\n",
    "players = fetch(SELECT + \"players\") # details of all players,\n",
    "players_teams = fetch(SELECT + \"players_teams\") # performance of each player for each team they played,\n",
    "series_post = fetch(SELECT + \"series_post\") # series' results,\n",
    "teams = fetch(SELECT + \"teams\") # performance of the teams for each season,\n",
    "teams_post = fetch(SELECT + \"teams_post\") # results of each team at the post-season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data in a dataframe\n",
    "awards_players_df = pd.DataFrame(awards_players, columns=['playerID', 'award', 'year', 'lgID'])\n",
    "coaches_df = pd.DataFrame(coaches, columns=['coachID', 'year', 'tmID', 'lgID', 'stint', 'won', 'lost', 'post_wins', 'post_losses'])\n",
    "players_df = pd.DataFrame(players, columns=['bioID', 'pos', 'firstseason', 'lastseason', 'height', 'weight', 'college', 'collegeOther', 'birthDate', 'deathDate'])\n",
    "players_teams_df = pd.DataFrame(players_teams, columns=['playerID', 'year', 'stint', 'tmID', 'lgID', 'GP', 'GS', 'minutes', 'points', 'oRebounds', 'dRebounds', 'rebounds', 'assists', 'steals', 'blocks', 'turnovers', 'PF', 'fgAttempted', 'fgMade', 'ftAttempted', 'ftMade', 'threeAttempted', 'threeMade', 'dq', 'PostGP', 'PostGS', 'PostMinutes', 'PostPoints', 'PostoRebounds', 'PostdRebounds', 'PostRebounds', 'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF', 'PostfgAttempted', 'PostfgMade', 'PostftAttempted', 'PostftMade', 'PostthreeAttempted', 'PostthreeMade', 'PostDQ'])\n",
    "series_post_df = pd.DataFrame(series_post, columns=['year', 'round', 'series', 'tmIDWinner', 'lgIDWinner', 'tmIDLoser', 'lgIDLoser', 'W', 'L'])\n",
    "teams_df = pd.DataFrame(teams, columns=['year', 'lgID', 'tmID', 'franchID', 'confID', 'divID', 'rank', 'playoff', 'seeded', 'firstRound', 'semis', 'finals', 'name', 'o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_reb', 'o_asts', 'o_pf', 'o_stl', 'o_to', 'o_blk', 'o_pts', 'd_fgm', 'd_fga', 'd_ftm', 'd_fta', 'd_3pm', 'd_3pa', 'd_oreb', 'd_dreb', 'd_reb', 'd_asts', 'd_pf', 'd_stl', 'd_to', 'd_blk', 'd_pts', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB', 'won', 'lost', 'GP', 'homeW', 'homeL', 'awayW', 'awayL', 'confW', 'confL', 'min', 'attend', 'arena'])\n",
    "teams_post_df = pd.DataFrame(teams_post, columns=['year', 'tmID', 'lgID', 'W', 'L'])\n",
    "\n",
    "#make a dictionary with all the dataframes\n",
    "dfs = {'awards_players_df': awards_players_df, 'coaches_df': coaches_df, 'players_df': players_df, 'players_teams_df': players_teams_df, 'series_post_df': series_post_df, 'teams_df': teams_df, 'teams_post_df': teams_post_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with a Exploratory Data Analysis. There are 7 different tables, with different sizes both in lines and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awards_players_df\n",
      "(95, 4) \n",
      "\n",
      "coaches_df\n",
      "(162, 9) \n",
      "\n",
      "players_df\n",
      "(893, 10) \n",
      "\n",
      "players_teams_df\n",
      "(1876, 43) \n",
      "\n",
      "series_post_df\n",
      "(70, 9) \n",
      "\n",
      "teams_df\n",
      "(142, 61) \n",
      "\n",
      "teams_post_df\n",
      "(80, 5) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for each table, print the table name, number of rows and columns\n",
    "for df in dfs:\n",
    "    print(df)\n",
    "    print(dfs[df].shape,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things we noticed is that all the tables have an \"League ID\" (lgID) attribute. As the WNBA is the only league we are covering, and there is no variability in this column, we can drop it, as well as other columns that may have always the same content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awards_players_df lgID\n",
      "coaches_df lgID\n",
      "players_df firstseason\n",
      "players_df lastseason\n",
      "players_teams_df lgID\n",
      "series_post_df lgIDWinner\n",
      "series_post_df lgIDLoser\n",
      "teams_df lgID\n",
      "teams_df divID\n",
      "teams_df seeded\n",
      "teams_df tmORB\n",
      "teams_df tmDRB\n",
      "teams_df tmTRB\n",
      "teams_df opptmORB\n",
      "teams_df opptmDRB\n",
      "teams_df opptmTRB\n",
      "teams_post_df lgID\n"
     ]
    }
   ],
   "source": [
    "#Drop columns whose values are always the same\n",
    "for df in dfs:\n",
    "    for col in dfs[df].columns:\n",
    "        if len(dfs[df][col].unique()) == 1:\n",
    "            print(df, col)\n",
    "            dfs[df].drop(col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, we also need to drop the death athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where death date is not 0000-00-00\n",
    "players_df = players_df[players_df['deathDate'] == '0000-00-00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tables with a lot of attributes (player_teams 43 and teams_df 61, for example). We will evaluate the correlations and delete the most correlated pairs of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CORRELATION = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_most_correlated(df):\n",
    "\n",
    "    players_teams_df_copy = df.copy()\n",
    "\n",
    "\n",
    "    correlation_matrix = players_teams_df_copy.corr()\n",
    "\n",
    "    sorted_correlations = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.show()\n",
    "\n",
    "    # Get the pairs of attributes with the highest correlation values\n",
    "    most_correlated_pairs = sorted_correlations[sorted_correlations > MAX_CORRELATION]\n",
    "    most_correlated_pairs = most_correlated_pairs[most_correlated_pairs < 1.0]\n",
    "\n",
    "\n",
    "    #delete repeated pairs (e.g. (a,b) and (b,a))\n",
    "    most_correlated_pairs = most_correlated_pairs[::2]\n",
    "    print(most_correlated_pairs)\n",
    "\n",
    "    #drop the attributes with the highest correlation values\n",
    "    for pair in most_correlated_pairs.index:\n",
    "        if pair[0] in players_teams_df_copy.columns:\n",
    "            players_teams_df_copy.drop(pair[0], inplace=True, axis=1)\n",
    "        if pair[1] in players_teams_df_copy.columns:\n",
    "            players_teams_df_copy.drop(pair[1], inplace=True, axis=1)\n",
    "\n",
    "    #print the attributes that were dropped\n",
    "    print(players_teams_df_copy.columns)\n",
    "    return players_teams_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the function for all the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awards_players_df\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'thompti01w'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/john/ac/notebook.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#to make the df actually change, we have to assign it to the df\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#df = delete_most_correlated(dfs[df])\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m delete_most_correlated(dfs[df])\n",
      "\u001b[1;32m/home/john/ac/notebook.ipynb Cell 25\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdelete_most_correlated\u001b[39m(df):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     players_teams_df_copy \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     correlation_matrix \u001b[39m=\u001b[39m players_teams_df_copy\u001b[39m.\u001b[39;49mcorr()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     sorted_correlations \u001b[39m=\u001b[39m correlation_matrix\u001b[39m.\u001b[39munstack()\u001b[39m.\u001b[39msort_values(ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/john/ac/notebook.ipynb#X65sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m20\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10707\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10705\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m  10706\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m> 10707\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m  10709\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10710\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:1892\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1891\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1892\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1893\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1894\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1656\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1657\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1713\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1714\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1715\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1716\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1718\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'thompti01w'"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df)\n",
    "    #to make the df actually change, we have to assign it to the df\n",
    "    #df = delete_most_correlated(dfs[df])\n",
    "    delete_most_correlated(dfs[df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
