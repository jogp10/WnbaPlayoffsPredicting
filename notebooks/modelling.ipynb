{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843b0d3d",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ac332",
   "metadata": {},
   "source": [
    "## Get the data from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ebe47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.492929300Z",
     "start_time": "2023-11-05T23:33:50.115650400Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "USE_MERGED_DATA = True\n",
    "\n",
    "#Get the data from the previous notebook, as csv files, and load them into dataframes\n",
    "awards_players_df = pd.read_csv('../prep_data/awards_players_df.csv')\n",
    "coaches_df = pd.read_csv('../prep_data/coaches_df.csv')\n",
    "players_df = pd.read_csv('../prep_data/players_df.csv')\n",
    "players_teams_df = pd.read_csv('../prep_data/players_teams_df.csv')\n",
    "series_post_df = pd.read_csv('../prep_data/series_post_df.csv')\n",
    "if USE_MERGED_DATA:\n",
    "    teams_df = pd.read_csv('../prep_data/teams_df_with_sum_of_3_best_attributes_of_players.csv')\n",
    "else:\n",
    "    teams_df = pd.read_csv('../prep_data/teams_df.csv')\n",
    "teams_post_df = pd.read_csv('../prep_data/teams_post_df.csv')\n",
    "\n",
    "#make a dictionary with all the dataframes\n",
    "dfs = {'awards_players_df': awards_players_df, 'coaches_df': coaches_df, 'players_df': players_df, 'players_teams_df': players_teams_df, 'series_post_df': series_post_df, 'teams_df': teams_df, 'teams_post_df': teams_post_df}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e8078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.639930500Z",
     "start_time": "2023-11-05T23:33:50.138585600Z"
    }
   },
   "outputs": [],
   "source": [
    "#Print all the dataframes\n",
    "for key in dfs:\n",
    "    print(key)\n",
    "    print(dfs[key].head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676924c",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "\n",
    "TARGET_NAMES = ['No Playoffs', 'Playoffs']\n",
    "N_FOLDS_CV = 10\n",
    "\n",
    "#see all null values in teams_df\n",
    "teams_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d27304e9ece233",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.683928100Z",
     "start_time": "2023-11-05T23:33:50.164392900Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(cm, target_names):\n",
    "    df_cm = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
    "    sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "def print_results(clf, X_train, X_test, y_train, y_test):\n",
    "    # Fit the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Create a confusion matrix to evaluate the model and print with labels\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print_confusion_matrix(cm, TARGET_NAMES)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def cross_validation(clf, X, y):\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS_CV, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Display the cross-validation results\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(\"Mean Accuracy: {:.2f}%\".format(scores.mean() * 100))\n",
    "    print(\"Standard Deviation: {:.2f}\".format(scores.std()))\n",
    "\n",
    "    return scores\n",
    "    \n",
    "def force_qualify_8_teams(y_pred, y_test):  \n",
    "    top_teams_indices = y_pred.argsort()[-8:][::-1]  # Get the indices of the top 8 teams\n",
    "\n",
    "    # Convert the labels to numeric format (0 for 'No Playoff', 1 for 'Playoff')\n",
    "    y_pred_numeric = [1 if i in top_teams_indices else 0 for i in range(len(y_pred))]\n",
    "    \n",
    "    # Calculate the accuracy of the modified predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred_numeric)\n",
    "    print(\"Modified Accuracy (Top 8 Teams as Playoff):\", accuracy)\n",
    "    \n",
    "    # Create a confusion matrix to evaluate the model and print with labels\n",
    "    cm = confusion_matrix(y_test, y_pred_numeric)\n",
    "    print_confusion_matrix(cm, TARGET_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f045b",
   "metadata": {},
   "source": [
    "## With current year info prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df3c68",
   "metadata": {},
   "source": [
    "Run a simple model on the teams table to predict if a team will make it to the playoffs or not. Let's see how it behaves.\n",
    "\n",
    "The main objective of this chapter is to find which is the model that performs the best, given the perfect data (the data from the year to be predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e9886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.736022300Z",
     "start_time": "2023-11-05T23:33:50.172181100Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train years and test year (year 10)\n",
    "teams_train_df = teams_df[teams_df['year'] < 10]\n",
    "teams_test_df = teams_df[teams_df['year'] == 10]\n",
    "\n",
    "cross_val_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03a8a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.795542700Z",
     "start_time": "2023-11-05T23:33:50.192253800Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = teams_train_df['playoff']\n",
    "y_test = teams_test_df['playoff']\n",
    "X_train = teams_train_df.drop(['playoff', 'year', 'tmID', 'firstRound', 'semis', 'finals'], axis=1)\n",
    "X_test = teams_test_df.drop(['playoff', 'year', 'tmID', 'firstRound', 'semis', 'finals'], axis=1)\n",
    "\n",
    "if USE_MERGED_DATA:\n",
    "    X_train = X_train.drop(['W_post', 'L_post'], axis=1)\n",
    "    X_test = X_test.drop(['W_post', 'L_post'], axis=1)\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "y_pred = print_results(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2eafc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.954082900Z",
     "start_time": "2023-11-05T23:33:50.493928300Z"
    }
   },
   "outputs": [],
   "source": [
    "force_qualify_8_teams(y_pred, y_test)\n",
    "\n",
    "scores = cross_validation(clf, X, y)\n",
    "cross_val_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "y_pred = print_results(knn_classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "force_qualify_8_teams(y_pred, y_test)\n",
    "\n",
    "scores = cross_validation(knn_classifier, X, y)\n",
    "cross_val_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "y_pred = print_results(knn_classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "force_qualify_8_teams(y_pred, y_test)\n",
    "\n",
    "scores = cross_validation(mnb_classifier, X, y)\n",
    "cross_val_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "    \n",
    "y_pred = print_results(mlp_classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "force_qualify_8_teams(y_pred, y_test)\n",
    "\n",
    "scores = cross_validation(mlp_classifier, X, y)\n",
    "cross_val_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(cross_val_scores, labels=['Random Forest', 'KNN', 'Multinomial NB', 'MLP'])\n",
    "plt.title('Cross-Validation Scores')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier seems to be performing better than the other classifiers.\n",
    "\n",
    "In the next chapter we will explore using a rolling window to use past years for the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2556d35",
   "metadata": {},
   "source": [
    "## Rolling window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling window functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efd014",
   "metadata": {},
   "source": [
    "We will use a rolling window to predict the next season. We will use the last 3 seasons to predict the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a78b5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:50.980071300Z",
     "start_time": "2023-11-05T23:33:50.733839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the rolling window size (number of past years to consider)\n",
    "ROLLING_WIN_SIZE = 8  # You can adjust this value\n",
    "PREDICTION_YEAR = 10\n",
    "\n",
    "historical_data_df = teams_df[teams_df['year'] < PREDICTION_YEAR]\n",
    "\n",
    "def create_rolling_window_dataset(df, window_size):\n",
    "    rolling_window_data = []\n",
    "    for tmID, group in df.groupby('tmID'):\n",
    "        group = group.sort_values(by='year')\n",
    "        for i in range(len(group) - window_size + 1):\n",
    "            window = group.iloc[i:i + window_size]\n",
    "            rolling_window_data.append(window)\n",
    "    return rolling_window_data\n",
    "\n",
    "def generate_weights(window_size):\n",
    "    weights = np.linspace(0.1, 1, window_size)\n",
    "    weights /= weights.sum()  # Normalize weights to ensure they sum to 1\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the rolling window dataset.\n",
    "In this dataset, three years are combined, with more weight given to the most recent year, and combining that historic data with the target variable (playoff) from the target year (the n+1 year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rolling window datasets\n",
    "rolling_window_historic = create_rolling_window_dataset(historical_data_df,  ROLLING_WIN_SIZE)\n",
    "\n",
    "# Define weights (you can adjust these weights as needed)\n",
    "weights = generate_weights(ROLLING_WIN_SIZE)\n",
    "\n",
    "weighted_features = ['o_fta', 'o_3pm', 'o_oreb', 'o_asts', 'o_stl', 'o_to', 'o_blk', 'd_3pa', 'd_oreb', 'd_dreb', 'd_asts', 'd_stl', 'd_to', 'd_blk', 'attend']\n",
    "\n",
    "if USE_MERGED_DATA:\n",
    "    weighted_features += ['num_seasons', 'height', 'weight', 'stint', 'GP', 'threeAttempted', 'dq', 'PostoRebounds', 'PostBlocks', 'PostthreeAttempted', 'PostDQ', 'FG%', 'FT%', 'Avg_Assists_Per_Game', 'Avg_Blocks_Per_Game', 'Avg_Steals_Per_Game', 'Points_Ratio', 'POSITION_METRIC']\n",
    "\n",
    "# Create a new dataframe to store the rolling window data\n",
    "rolling_data = pd.DataFrame(columns=teams_df.columns)\n",
    "\n",
    "for window in rolling_window_historic:\n",
    "    #For each window, we will add a line to the rolling_data dataframe, as follows:\n",
    "    #1. Create a new empty line for the rolling_data dataframe\n",
    "    rolling_data_line = pd.DataFrame(columns=teams_df.columns)\n",
    "\n",
    "    #2. Get the weighted average of the weighted features\n",
    "    #Note: The weighted average is calculated as follows:\n",
    "    #weighted average = sum of (weight * feature value) / sum of weights\n",
    "    #For example, if the weights are [0.2, 0.3, 0.5] and the feature values are [10, 20, 30], then the weighted average is:\n",
    "    #weighted average = (0.2 * 10 + 0.3 * 20 + 0.5 * 30) / (0.2 + 0.3 + 0.5) = 24\n",
    "    for feature in weighted_features:\n",
    "        weighted_average = np.average(window[feature].values, weights=weights)\n",
    "        rolling_data_line[feature] = [weighted_average]\n",
    "\n",
    "    #3. Join that data with the data from the following year (the year we want to predict)\n",
    "    #Note: The data from the following year will be used as the target label, get next year from the teams_df dataframe\n",
    "    next_year = window['year'].max() + 1\n",
    "    next_year_data = teams_df[(teams_df['tmID'] == window['tmID'].values[0]) & (teams_df['year'] == next_year)]\n",
    "\n",
    "    #Add year, confID, tmID, and playoff columns\n",
    "    try:\n",
    "        rolling_data_line['year'] = next_year\n",
    "        rolling_data_line['tmID'] = window['tmID'].values[0]\n",
    "        rolling_data_line['confID'] = next_year_data['confID'].values[0]\n",
    "        rolling_data_line['playoff'] = next_year_data['playoff'].values[0]\n",
    "    except:\n",
    "        #If there is no data for the next year, skip this line\n",
    "        #print('No data for next year')\n",
    "        continue\n",
    "    \n",
    "    #4. Concat the data to the rolling_data dataframe\n",
    "    rolling_data = pd.concat([rolling_data, rolling_data_line])\n",
    "\n",
    "rolling_data = rolling_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafde03cbdc1cd88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:52.246618Z",
     "start_time": "2023-11-05T23:33:50.748554200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = rolling_data[rolling_data['year'] < 10]['playoff'].astype(int)\n",
    "y_test = rolling_data[rolling_data['year'] == 10]['playoff'].astype(int)\n",
    "X_train = rolling_data[rolling_data['year'] < 10].drop(['playoff', 'year', 'tmID', 'firstRound', 'semis', 'finals'], axis=1)\n",
    "X_test = rolling_data[rolling_data['year'] == 10].drop(['playoff', 'year', 'tmID', 'firstRound', 'semis', 'finals'], axis=1)\n",
    "\n",
    "if USE_MERGED_DATA:\n",
    "    X_train = X_train.drop(['W_post', 'L_post'], axis=1)\n",
    "    X_test = X_test.drop(['W_post', 'L_post'], axis=1)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "display(X_train.head())\n",
    "\n",
    "scores = cross_validation(clf, X, y)\n",
    "\n",
    "y_pred = print_results(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40efb52aa11b8e48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T23:33:52.423248600Z",
     "start_time": "2023-11-05T23:33:52.245623Z"
    }
   },
   "outputs": [],
   "source": [
    "force_qualify_8_teams(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
