{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a474e2",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb42898",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aeeee5",
   "metadata": {},
   "source": [
    "We used a free service to host our database. The Database is in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Credentials\n",
    "\n",
    "with open(\"../config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "host = config[\"db_host\"]\n",
    "user = config[\"db_user\"]\n",
    "password = config[\"db_password\"]\n",
    "database = config[\"db_database\"]\n",
    "schema = config[\"db_schema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "def execute(query):\n",
    "    cursor.execute(query)\n",
    "    connection.commit()\n",
    "    return cursor.fetchall()\n",
    "\n",
    "def fetch(query):\n",
    "    cursor.execute(query)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "SELECT = \"SELECT * FROM \" + schema + \".\" # + table_name \n",
    "INSERT = \"INSERT INTO \" + schema + \".\" # + table_name + \" VALUES \" + values\n",
    "UPDATE = \"UPDATE \" + schema + \".\" # + table_name + \" SET \" + column_name + \" = \" + value\n",
    "DELETE = \"DELETE FROM \" + schema + \".\"  # + table_name + \" WHERE \" + column_name + \" = \" + value\n",
    "\n",
    "# Test data, year 10\n",
    "TEST_DATA = \"year = 10\"\n",
    "TRAIN_DATA = \"year < 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44416216",
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players = fetch(SELECT + \"awards_players\") # awards and prizes received by players across 10 seasons,\n",
    "coaches = fetch(SELECT + \"coaches\") # all coaches who've managed the teams during the time period,\n",
    "players = fetch(SELECT + \"players\") # details of all players,\n",
    "players_teams = fetch(SELECT + \"players_teams\") # performance of each player for each team they played,\n",
    "series_post = fetch(SELECT + \"series_post\") # series' results,\n",
    "teams = fetch(SELECT + \"teams\") # performance of the teams for each season,\n",
    "teams_post = fetch(SELECT + \"teams_post\") # results of each team at the post-season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4454347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data in a dataframe\n",
    "awards_players_df = pd.DataFrame(awards_players, columns=['playerID', 'award', 'year', 'lgID'])\n",
    "coaches_df = pd.DataFrame(coaches, columns=['coachID', 'year', 'tmID', 'lgID', 'stint', 'won', 'lost', 'post_wins', 'post_losses'])\n",
    "players_df = pd.DataFrame(players, columns=['bioID', 'pos', 'firstseason', 'lastseason', 'height', 'weight', 'college', 'collegeOther', 'birthDate', 'deathDate'])\n",
    "players_teams_df = pd.DataFrame(players_teams, columns=['playerID', 'year', 'stint', 'tmID', 'lgID', 'GP', 'GS', 'minutes', 'points', 'oRebounds', 'dRebounds', 'rebounds', 'assists', 'steals', 'blocks', 'turnovers', 'PF', 'fgAttempted', 'fgMade', 'ftAttempted', 'ftMade', 'threeAttempted', 'threeMade', 'dq', 'PostGP', 'PostGS', 'PostMinutes', 'PostPoints', 'PostoRebounds', 'PostdRebounds', 'PostRebounds', 'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF', 'PostfgAttempted', 'PostfgMade', 'PostftAttempted', 'PostftMade', 'PostthreeAttempted', 'PostthreeMade', 'PostDQ'])\n",
    "series_post_df = pd.DataFrame(series_post, columns=['year', 'round', 'series', 'tmIDWinner', 'lgIDWinner', 'tmIDLoser', 'lgIDLoser', 'W', 'L'])\n",
    "teams_df = pd.DataFrame(teams, columns=['year', 'lgID', 'tmID', 'franchID', 'confID', 'divID', 'rank', 'playoff', 'seeded', 'firstRound', 'semis', 'finals', 'name', 'o_fgm', 'o_fga', 'o_ftm', 'o_fta', 'o_3pm', 'o_3pa', 'o_oreb', 'o_dreb', 'o_reb', 'o_asts', 'o_pf', 'o_stl', 'o_to', 'o_blk', 'o_pts', 'd_fgm', 'd_fga', 'd_ftm', 'd_fta', 'd_3pm', 'd_3pa', 'd_oreb', 'd_dreb', 'd_reb', 'd_asts', 'd_pf', 'd_stl', 'd_to', 'd_blk', 'd_pts', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB', 'won', 'lost', 'GP', 'homeW', 'homeL', 'awayW', 'awayL', 'confW', 'confL', 'min', 'attend', 'arena'])\n",
    "teams_post_df = pd.DataFrame(teams_post, columns=['year', 'tmID', 'lgID', 'W', 'L'])\n",
    "\n",
    "#make a dictionary with all the dataframes\n",
    "dfs = {'awards_players_df': awards_players_df, 'coaches_df': coaches_df, 'players_df': players_df, 'players_teams_df': players_teams_df, 'series_post_df': series_post_df, 'teams_df': teams_df, 'teams_post_df': teams_post_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17109c4",
   "metadata": {},
   "source": [
    "So with that we end our understanding phase.\n",
    "Our main takeaways are:\n",
    "- There are dead players in the players table. We should take that into account when doing the analysis.\n",
    "- There are players that have not played any season of the seasons given. We should take that into account when doing the analysis. There are 338 players that have not played any season.\n",
    "- There are no Null entries (although there values that are simply an empty string)\n",
    "- There are some columns with the DataType \"object\", most of them being strings.\n",
    "- There are binary objects (like confID and playoff, in the 'teams' table, with the values \"Y\" or \"N\") that could be substituted by a binary, as well as ternary objects (like the firstRound, semis and finals in the 'teams' table, with the values \"W\", \"L\" or \"\") that could also be transformed.\n",
    "- There are players with no position and no college assigned (\"\").\n",
    "- There are players with no date of birth in the record (0000-00-00).\n",
    "- There is the need to do null value uniformization, as there are some columns with empty strings, others with default 0 values and other values that represent null.\n",
    "- The height and weight variables have default 0 values and should be treated as null values.\n",
    "- The number of games played by each team differs (there may be teams that are no longer playing), so we can't compare the number of wins and losses directly. Win percentage should be used.\n",
    "- In terms of win percentage, it seems like a competitive league, with more than half of the teams having a win percentage of 50% or more, taking advantage of the worst teams. There is also just one team below 40% of wins.\n",
    "- There are teams that are no longer playing.\n",
    "- There are a lot of highly correlated variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601ae40",
   "metadata": {},
   "source": [
    "## Preparing the data for the model\n",
    "\n",
    "In this notebook, we will prepare the data for the model. Having done the understanding in the [previous notebook](understanding.ipynb), we will now prepare the data for the model. From the understanding we came to the following conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642023b",
   "metadata": {},
   "source": [
    "So with that we end our understanding phase.\n",
    "Our main takeaways are:\n",
    "- There are dead players in the players table. We should take that into account when doing the analysis.\n",
    "- There are players that have not played any season of the seasons given. We should take that into account when doing the analysis. There are 338 players that have not played any season.\n",
    "- There are no Null entries (although there values that are simply an empty string)\n",
    "- There are some columns with the DataType \"object\", most of them being strings.\n",
    "- There are binary objects (like confID and playoff, in the 'teams' table, with the values \"Y\" or \"N\") that could be substituted by a binary, as well as ternary objects (like the firstRound, semis and finals in the 'teams' table, with the values \"W\", \"L\" or \"\") that could also be transformed.\n",
    "- There are players with no position and no college assigned (\"\").\n",
    "- There are players with no date of birth in the record (0000-00-00).\n",
    "- There is the need to do null value uniformization, as there are some columns with empty strings, others with default 0 values and other values that represent null.\n",
    "- The height and weight variables have default 0 values and should be treated as null values.\n",
    "- The number of games played by each team differs (there may be teams that are no longer playing), so we can't compare the number of wins and losses directly. Win percentage should be used.\n",
    "- In terms of win percentage, it seems like a competitive league, with more than half of the teams having a win percentage of 50% or more, taking advantage of the worst teams. There is also just one team below 40% of wins.\n",
    "- There are teams that are no longer playing.\n",
    "- There are a lot of highly correlated variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90834ca",
   "metadata": {},
   "source": [
    "After considering our takeaways, we will now prepare the data for the model. We will do the following:\n",
    "- Remove the players that have not played any season, and, if a player died, remove the seasons after the death.\n",
    "- Transform the binary objects into binary values.\n",
    "- Transform the ternary objects into binary values. (where the third value is a null value)\n",
    "- Null uniformization: transform the empty strings and default 0 values into null values.\n",
    "- Analysis null values: analyze the null values and decide what to do with them.\n",
    "- Calculate win percentage for each team and add it to the teams table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f2ce92",
   "metadata": {},
   "source": [
    "We start by dropping the columns that are always the same, as they don't add any information to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a375c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns whose values are always the same\n",
    "for df in dfs:\n",
    "    for col in dfs[df].columns:\n",
    "        if len(dfs[df][col].unique()) == 1:\n",
    "            print(df, col)\n",
    "            dfs[df].drop(col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907828e",
   "metadata": {},
   "source": [
    "### Remove the players that have not played any season, and, if a player died, remove the seasons after the death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#players that have not played in the last 10 years\n",
    "players_not_played = fetch(\"SELECT p.bioid FROM wnba.players p WHERE p.bioid not in (select pt.playerid  from wnba.players_teams pt)\")\n",
    "#Convert list of tuples to list\n",
    "players_not_played = [i[0] for i in players_not_played]\n",
    "players_not_played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861dba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the number of players that have not played in the last 10 years, and the lenght of the 3 dataframes that contain the playerID\n",
    "print(\"Number of players that have not played: \", len(players_not_played))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Number of values in the players_team_df: \", len(dfs['players_teams_df']['playerID'].unique()))\n",
    "print(\"Number of values in the awards_players_df: \", len(dfs['awards_players_df']['playerID'].unique()))\n",
    "print(\"Number of values in the players_df: \", len(dfs['players_df']['bioID'].unique()))\n",
    "\n",
    "#Remove the players that have not played in the last 10 years\n",
    "for df in dfs:\n",
    "    if(df == 'players_teams_df' or df == 'awards_players_df'):\n",
    "        dfs[df] = dfs[df][~dfs[df]['playerID'].isin(players_not_played)]\n",
    "    if(df == 'players_df'):\n",
    "        dfs[df] = dfs[df][~dfs[df]['bioID'].isin(players_not_played)]\n",
    "\n",
    "#Print the number of players that have not played in the last 10 years, and the lenght of the 3 dataframes that contain the playerID\n",
    "print(\"Number of values in the players_team_df: \", len(dfs['players_teams_df']['playerID'].unique()))\n",
    "print(\"Number of values in the awards_players_df: \", len(dfs['awards_players_df']['playerID'].unique()))\n",
    "print(\"Number of values in the players_df: \", len(dfs['players_df']['bioID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304bca3",
   "metadata": {},
   "source": [
    "### Transform the binary objects into binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3e7a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awards_players_df', []),\n",
       " ('coaches_df', []),\n",
       " ('players_df', ['deathDate']),\n",
       " ('players_teams_df', []),\n",
       " ('series_post_df', ['W']),\n",
       " ('teams_df', ['confID', 'playoff', 'GP']),\n",
       " ('teams_post_df', [])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all the binary columns from all the dataframes\n",
    "binary_columns = []\n",
    "for df in dfs:\n",
    "    binary_columns = binary_columns + [(df, list(dfs[df].columns[dfs[df].nunique() == 2]))]\n",
    "\n",
    "binary_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0f9b3",
   "metadata": {},
   "source": [
    "Death date being a binary value is a coincidence, as only one player (that has played in the seasons we have) has died.\n",
    "GP is the number of games played and should also not be converted to binary, as we will need this value to calculate the win percentage. (it is only binary because seasons have been of 32 games or 34 games). The W value in the series_post represents the number of wins a team winned in the playoffs. All the playoffs games are in the best of 3 or 5, so the winning team wins 2 or 3 games.\n",
    "The other binary values are binary and should be converted to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9d5f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the binary columns to 0 and 1\n",
    "#Convert confID to 0 and 1\n",
    "dfs['teams_df']['confID'] = dfs['teams_df']['confID'].replace(['E', 'W'], [0, 1])\n",
    "#Convert playoff to 0 and 1\n",
    "dfs['teams_df']['playoff'] = dfs['teams_df']['playoff'].replace(['N', 'Y'], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253fc10b",
   "metadata": {},
   "source": [
    "### Transform the ternary objects into binary values. (where the third value is a null value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe101729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1896a31c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
